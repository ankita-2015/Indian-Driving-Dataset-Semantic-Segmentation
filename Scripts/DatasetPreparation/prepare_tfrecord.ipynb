{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t2WiNacIt8vi",
    "outputId": "2bf773d4-c625-4656-d257-c9f7fde97bb2"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4iTl-z4Pt8pv",
    "outputId": "138a1325-6a88-4adf-c0c0-32c4f8047fc3"
   },
   "outputs": [],
   "source": [
    "# !pip install q tensorflow==2.1\n",
    "# !pip install q keras==2.3.1\n",
    "# !pip install git+https://github.com/qubvel/segmentation_models\n",
    "\n",
    "# for str decode error ... run it and restart runtime\n",
    "# !pip uninstall h5py -y\n",
    "!pip install h5py==2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = !ls Dataset/images/\n",
    "l = !ls Dataset/masks/\n",
    "len(i), len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l[-5:], i[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GntQ2vuNt8gL"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 100 = background\n",
    "# 101 = road\n",
    "# 102 = obstacle\n",
    "\n",
    "l = glob('Dataset/masks/*')\n",
    "m = cv2.imread(l[2970],0)\n",
    "m.shape\n",
    "np.unique(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JLjUhiwat8Wu",
    "outputId": "8d64a866-f250-4843-961f-1eb71f81fe43"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "len(os.listdir('Dataset/images/')), len(os.listdir('Dataset/masks/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "def load_dataset(dataset_path):\n",
    "    images = sorted(glob(os.path.join(dataset_path, \"images/*\")))\n",
    "    masks = sorted(glob(os.path.join(dataset_path, \"masks/*\")))\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(images,masks, test_size=0.168, \n",
    "                                                        random_state=168, shuffle=True)\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "train_x, train_y, val_x, val_y = load_dataset('Dataset')\n",
    "print(len(train_x), len(train_y), len(val_x), len(val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"Build a TF Record for Cityscapes Semantic Segmentation dataset.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import hashlib\n",
    "import glob\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "\n",
    "def _bytes_feature(values):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))\n",
    "\n",
    "def _int64_feature(values):\n",
    "    if not isinstance(values, (tuple, list)):\n",
    "        values = [values]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=values))\n",
    "\n",
    "def _open_file(full_path):\n",
    "    with tf.io.gfile.GFile(full_path, 'rb') as fid:\n",
    "        encoded_file = fid.read()\n",
    "        encoded_file_io = io.BytesIO(encoded_file)\n",
    "        image = PIL.Image.open(encoded_file_io)\n",
    "    return image, encoded_file\n",
    "\n",
    "def create_tf_example(image_path, label_path, image_dir='', is_jpeg=False):\n",
    "    file_format = 'jpeg' if is_jpeg else 'png'\n",
    "    full_image_path = os.path.join(image_dir, image_path)\n",
    "    full_label_path = os.path.join(image_dir, label_path)\n",
    "    image, encoded_image = _open_file(full_image_path)\n",
    "    label,encoded_label = _open_file(full_label_path)\n",
    "    height = image.height\n",
    "    width = image.width\n",
    "\n",
    "    if height != label.height or width != label.width:\n",
    "        raise ValueError('Input and annotated images must have same dims.''verify the matching pair for {}'.format(full_image_path))\n",
    "\n",
    "    feature_dict = {'image/encoded': _bytes_feature(encoded_image),\n",
    "                    'image/filename': _bytes_feature(full_image_path.encode('utf8')),\n",
    "                    'image/format': _bytes_feature(file_format.encode('utf8')),\n",
    "                    'image/height': _int64_feature(height),\n",
    "                    'image/width': _int64_feature(width),\n",
    "                    'image/channels': _int64_feature(3),\n",
    "                    'image/segmentation/class/encoded': _bytes_feature(encoded_label),\n",
    "                    'image/segmentation/class/format':_bytes_feature('png'.encode('utf8')),\n",
    "                    }\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n",
    "    return example\n",
    "            \n",
    "def _create_tf_record(images, labels, output_path):\n",
    "    writer = tf.io.TFRecordWriter(output_path)\n",
    "    for idx, image in enumerate(images):\n",
    "        if idx % 500 == 0:\n",
    "            tf.compat.v1.logging.info('On image %d of %d', idx, len(images))\n",
    "        tf_example = create_tf_example(image, labels[idx], is_jpeg=False)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "    tf.compat.v1.logging.info('Finished writing!')\n",
    "\n",
    "_create_tf_record(train_x,train_y,output_path=\"Dataset/train_cs.record\")\n",
    "_create_tf_record(val_x,val_y,output_path=\"Dataset/val_cs.record\")\n",
    "# _create_tf_record(val_x,val_y,output_path=\"Dataset/val_cs.record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_dataset = tf.data.TFRecordDataset(\"Dataset/val_cs.record\")\n",
    "# raw_dataset\n",
    "# for raw_record in raw_dataset.take(1):\n",
    "#     example = tf.train.Example()\n",
    "#     example.ParseFromString(raw_record.numpy())\n",
    "#     print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Welcome To Colaboratory",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
